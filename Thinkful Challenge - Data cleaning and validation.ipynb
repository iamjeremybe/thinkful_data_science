{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will need to do considerable data cleaning in order to extract accurate estimates, and may want to look into data encoding methods if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('apcs/welcome2013.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out what we have\n",
    "\n",
    "We can make sure we read something that looks sensible, and check the basic stats of the data we read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID/PMCID</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Journal title</th>\n",
       "      <th>Article title</th>\n",
       "      <th>COST (£) charged to Wellcome (inc VAT when charged)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CUP</td>\n",
       "      <td>Psychological Medicine</td>\n",
       "      <td>Reduced parahippocampal cortical thickness in ...</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC3679557</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Biomacromolecules</td>\n",
       "      <td>Structural characterization of a Model Gram-ne...</td>\n",
       "      <td>£2381.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23043264  PMC3506128</td>\n",
       "      <td>ACS</td>\n",
       "      <td>J Med Chem</td>\n",
       "      <td>Fumaroylamino-4,5-epoxymorphinans and related ...</td>\n",
       "      <td>£642.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23438330 PMC3646402</td>\n",
       "      <td>ACS</td>\n",
       "      <td>J Med Chem</td>\n",
       "      <td>Orvinols with mixed kappa/mu opioid receptor a...</td>\n",
       "      <td>£669.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23438216 PMC3601604</td>\n",
       "      <td>ACS</td>\n",
       "      <td>J Org Chem</td>\n",
       "      <td>Regioselective opening of myo-inositol orthoes...</td>\n",
       "      <td>£685.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PMID/PMCID Publisher           Journal title  \\\n",
       "0                    NaN       CUP  Psychological Medicine   \n",
       "1             PMC3679557       ACS       Biomacromolecules   \n",
       "2  23043264  PMC3506128        ACS              J Med Chem   \n",
       "3    23438330 PMC3646402       ACS              J Med Chem   \n",
       "4   23438216 PMC3601604        ACS              J Org Chem   \n",
       "\n",
       "                                       Article title  \\\n",
       "0  Reduced parahippocampal cortical thickness in ...   \n",
       "1  Structural characterization of a Model Gram-ne...   \n",
       "2  Fumaroylamino-4,5-epoxymorphinans and related ...   \n",
       "3  Orvinols with mixed kappa/mu opioid receptor a...   \n",
       "4  Regioselective opening of myo-inositol orthoes...   \n",
       "\n",
       "  COST (£) charged to Wellcome (inc VAT when charged)  \n",
       "0                                              £0.00   \n",
       "1                                           £2381.04   \n",
       "2                                            £642.56   \n",
       "3                                            £669.64   \n",
       "4                                            £685.88   "
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID/PMCID</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Journal title</th>\n",
       "      <th>Article title</th>\n",
       "      <th>COST (£) charged to Wellcome (inc VAT when charged)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1928</td>\n",
       "      <td>2127</td>\n",
       "      <td>2126</td>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1880</td>\n",
       "      <td>299</td>\n",
       "      <td>984</td>\n",
       "      <td>2126</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>Exclusive breastfeeding, diarrhoel morbidity a...</td>\n",
       "      <td>£2040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>387</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID/PMCID Publisher Journal title  \\\n",
       "count        1928      2127          2126   \n",
       "unique       1880       299           984   \n",
       "top             -  Elsevier      PLoS One   \n",
       "freq            7       387            92   \n",
       "\n",
       "                                            Article title  \\\n",
       "count                                                2127   \n",
       "unique                                               2126   \n",
       "top     Exclusive breastfeeding, diarrhoel morbidity a...   \n",
       "freq                                                    2   \n",
       "\n",
       "       COST (£) charged to Wellcome (inc VAT when charged)  \n",
       "count                                                2127   \n",
       "unique                                               1402   \n",
       "top                                              £2040.00   \n",
       "freq                                                   94   "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic cleanup - renaming columns\n",
    "\n",
    "We can rename the columns to make them easier to handle. The first word of each column header is descriptive enough and doesn't contain hard to type characters like '£'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PMID/PMCID', 'Publisher', 'Journal', 'Article', 'COST'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to make our lives easier\n",
    "df.rename(lambda x: str.split(x,' ')[0],axis='columns',inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMID/PMCID\n",
    "\n",
    "PMID is a unique identifier for articles published in PubMed, [an index of the biomedical literature](https://nexus.od.nih.gov/all/2015/08/31/pmid-vs-pmcid-whats-the-difference/) according to NIH. PMCID is a number assigned to articles in a PubMed archive. This column is kind of a mess in that around 200 rows don't have a valid value. Fortunately, I don't think we need to care much about this column in the analysis we're asked to do.\n",
    "\n",
    "### Duplicate values\n",
    "\n",
    "I see that there are some duplicated values in the PMID/PMCID column--they are mostly invalid or placeholder values. I didn't see anything with a valid value in this column that was a duplicate.\n",
    "\n",
    "There is one duplicate article title--this DOES represent a duplicate value, so I'm deleting one of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PMID/PMCID                  Publisher   Journal  \\\n",
      "1490    Pending  Public Library of Science  PLoS One   \n",
      "1496        NaN  Public Library of Science  PLoS One   \n",
      "\n",
      "                                                Article     COST  \n",
      "1490  Exclusive breastfeeding, diarrhoel morbidity a...  £825.68  \n",
      "1496  Exclusive breastfeeding, diarrhoel morbidity a...  £825.68  \n"
     ]
    }
   ],
   "source": [
    "duplicate_title = df.loc[df['Article'].duplicated() == True]['Article']\n",
    "for i in duplicate_title:\n",
    "    print(df.loc[df['Article'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(1496, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost column cleanup\n",
    "\n",
    "Values in the cost column have a lot of leading £ signs, and a handful of trailing $ signs.\n",
    "\n",
    "We can strip the leading pound signs.\n",
    "\n",
    "This column is supposed to be in £, so I think where we see dollar signs, we should convert those values from dollars to pounds. There are no dates in this data, but the introduction to this challenge said \"between 2012 and 2013\", so I grabbed the average annual exchange rates for 2012-2013 from [this site](https://www.ofx.com/en-us/forex-news/historical-exchange-rates/yearly-average-rates/):\n",
    "\n",
    "`\n",
    "December 31, 2012\t0.631109\n",
    "December 31, 2013\t0.63955\n",
    "`\n",
    "\n",
    "The mean of those two values is 0.6353295--let's use that for our conversion.\n",
    "\n",
    "The Cost column contains some instances of 999999.00, which are obviously bogus. There are also a few values that are what I would consider unreasonably large compared to the rest of the data--arguably the MacMillan article that costs 13200.00 is one of these, but certainly nothing larger than that can be real.\n",
    "\n",
    "Because there aren't a large number of these bogus values, I feel like it's safe to set them to 'NaN'. We can still compute summary stats on the values that are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6353295"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of 2012-2013 dollars to pounds conversion rates\n",
    "np.mean((0.631109,0.63955))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert COST to floats, representing values in pounds.\n",
    "def strip_or_convert(cost):\n",
    "    final_value = float('NaN')\n",
    "# 999999.00 is an obviously bogus value. Immediately replace with NaN.\n",
    "    if (cost.find('999999.00') != -1):\n",
    "        return final_value\n",
    "# Strip pound signs\n",
    "    elif cost.startswith('£'):\n",
    "        final_value = round(float(cost.strip('£')), 2)\n",
    "# Convert dollars to pounds\n",
    "    elif cost.endswith('$'):\n",
    "        final_value = round(0.6353295 * float(cost.strip('$')), 2)\n",
    "    else:\n",
    "# I don't think we'll ever use this condition...?\n",
    "        print(\"This cost is weird: {}\".format(cost))\n",
    "        final_value = cost\n",
    "# I saw a few huge values that weren't 999999.00 but which still didn't make sense.\n",
    "    return final_value if final_value < 15000.00 else float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also rename this column to something slightly friendlier while we're here.\n",
    "df['Cost'] = df['COST'].apply(strip_or_convert)\n",
    "df.drop(['COST'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2077.000000\n",
       "mean      1824.710419\n",
       "std        809.401251\n",
       "min          0.000000\n",
       "25%       1260.000000\n",
       "50%       1851.290000\n",
       "75%       2302.930000\n",
       "max      13200.000000\n",
       "Name: Cost, dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cost'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher cleanup\n",
    "\n",
    "Publisher names are all over the place--multiple similar but not exact names, abbreviations, with and without company types (Ltd., Inc., LLC). I want to clean those up so we can get an accurate count of articles published for each publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip spaces from around the publishers' names\n",
    "df['Publisher'] = df['Publisher'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wrote a function to help standardize some of the publishers' names.\n",
    "# It adds pairs of raw/standardized names to a dict, which we use later\n",
    "#  in a replace method.\n",
    "publisher_dict = {}\n",
    "\n",
    "def publisher_cleanup(df_loc,repl_str):\n",
    "    for pub in df_loc:\n",
    "        publisher_dict[pub] = repl_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a lengthy section containing all of my attempts to consolidate similarly-named publishers.\n",
    "\n",
    "I realized after I was well into this section that I may have been able to avoid some of this work by dropping the leading word \"The\" from all publisher names, and maybe dropping \", Inc/Ltd/LLC\" from the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:222: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "# ACS = American Chemical Society and various permutations\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('ACS') \\\n",
    "                                      | df['Publisher'].str.contains('American Chemical Society', case=False)].unique(),\n",
    "                  'American Chemical Society'\n",
    "                 )\n",
    "\n",
    "# ASBMB = American Society for Biochemistry and Molecular Biology.\n",
    "# Cenveo is a publisher service, and \"trusted service provider\" to ASBMB,\n",
    "#  so I think it's fair to roll \"ASBMB/Cenveo\" entries into this one.\n",
    "# I didn't find anything for 'AMBSB' when I Googled, so I think that is a misspelling of 'ASBMB'.\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Biochemistry and Molecular Biol',case=False) \\\n",
    "                                     | df['Publisher'].str.contains('ASBMB') \\\n",
    "                                     | (df['Publisher'] == 'AMBSB')].unique(),\n",
    "                 'American Society for Biochemistry and Molecular Biology'\n",
    "                 )\n",
    "\n",
    "# American Society of Hematology\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('H.*matology', case=False)].unique(),\n",
    "                 'American Society of Hematology'\n",
    "                 )\n",
    "\n",
    "# American Society for Biochemistry and Molecular Biology\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('American Society for Biochemistry and Molecular Biology')].unique(),\n",
    "                 'American Society for Biochemistry and Molecular Biology'\n",
    "                 )\n",
    "\n",
    "# ASM - American Society for Microbiology\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('American Society (of|for) Microbiology',case=False) \\\n",
    "                                     | df['Publisher'].str.startswith('ASM')].unique(),\n",
    "                 'American Society for Microbiology'\n",
    "                 )\n",
    "\n",
    "# Bentham Science Publishers\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Benthan', case=False)].unique(),\n",
    "                 'Bentham Science Publishers'\n",
    "                 )\n",
    "\n",
    "# BioMed Central\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('BioMed', case=False)].unique(),\n",
    "                 'BioMed Central'\n",
    "                 )\n",
    "\n",
    "# Bioscientifica does not have a capitalized S in the middle\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('BioScient')].unique(),\n",
    "                 'Bioscientifica'\n",
    "                 )\n",
    "\n",
    "# BMJ = British Medical Journal\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('BMJ')].unique(),\n",
    "                 'British Medical Journal'\n",
    "                 )\n",
    "\n",
    "# Cadmus\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Cadmus',case=False)].unique(),\n",
    "                  'Cadmus'\n",
    "                 )\n",
    "\n",
    "# Cambridge University Press\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Cambridge',case=False)].unique(),\n",
    "                  'Cambridge University Press'\n",
    "                 )\n",
    "\n",
    "# Cenveo\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('Cenveo')].unique(),\n",
    "                 'Cenveo Publisher Services',\n",
    "                 )\n",
    "\n",
    "# Cold Spring Harbor\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Cold Spring Ha.?bo.*r',case=False)].unique(),\n",
    "                 'Cold Spring Harbor'\n",
    "                 )\n",
    "\n",
    "# Company of Biologists\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Company of Biol.*gist', case=False)].unique(),\n",
    "                 'Company of Biologists'\n",
    "                 )\n",
    "\n",
    "# Dartmouth Journal Services\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Dar.?mouth',case=False)].unique(),\n",
    "                 'Dartmouth Journal Services'\n",
    "                 )\n",
    "\n",
    "# Elsevier\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('^Elsev.*r', case=False)].unique(),\n",
    "                 'Elsevier'\n",
    "                 )\n",
    "\n",
    "# The Endocrine Society\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Endocrine', case=False)].unique(),\n",
    "                 'The Endocrine Society'\n",
    "                 )\n",
    "\n",
    "# Federation of American Societies for Experimental Biology\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains('Experimental Biology', case=False)) \\\n",
    "                                     | (df['Publisher'] == 'FASEB')].unique(),\n",
    "                 'Federation of American Societies for Experimental Biology'\n",
    "                 )\n",
    "\n",
    "# Frontiers Media SA\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.startswith('Frontiers Media')) \\\n",
    "                   | (df['Publisher'] == 'Frontiers')].unique(),\n",
    "                 'Frontiers Media SA'\n",
    "                 )\n",
    "\n",
    "# Future Medicine\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Future Medicine')].unique(),\n",
    "                 'Future Medicine'\n",
    "                 )\n",
    "\n",
    "# Hindawi\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('Hindawi')].unique(),\n",
    "                 'Hindawi'\n",
    "                 )\n",
    "\n",
    "# Impact Journals\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('Impact')].unique(),\n",
    "                 'Impact Journals'\n",
    "                 )\n",
    "\n",
    "# International Union Against Tuberculosis and Lung Disease\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Tuberculosis and Lung Disease', case=False)].unique(),\n",
    "                 'International Union Against Tuberculosis and Lung Disease'\n",
    "                 )\n",
    "\n",
    "# Informa Healthcare\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('Informa Healthcare')].unique(),\n",
    "                  'Informa Healthcare'\n",
    "                 )\n",
    "\n",
    "# International Union of Crystallography\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('International Union of Crystallography')].unique(),\n",
    "                 'International Union of Crystallography'\n",
    "                 )\n",
    "\n",
    "# Karger\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Karger', case=False)].unique(),\n",
    "                 'Karger'\n",
    "                 )\n",
    "\n",
    "# Landes Bioscience\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith('Landes Biosciences')].unique(),\n",
    "                 'Landes Bioscience'\n",
    "                 )\n",
    "\n",
    "# Mary Ann Liebert\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Mary Ann Liebert', case=False)].unique(),\n",
    "                 'Mary Ann Liebert'\n",
    "                 )\n",
    "\n",
    "# MIT Press\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('MIT Press', case=False)].unique(),\n",
    "                  'MIT Press'\n",
    "                 )\n",
    "\n",
    "# MYJoVE\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains('JoVE', case=False)) \\\n",
    "                                     | df['Publisher'].str.contains('Journal of Visualized Experiments')].unique(),\n",
    "                 'MYJoVE')\n",
    "\n",
    "# PNAS = Proceedings of the National Academcy of Sciences\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains('National Academy of Sciences', case=False)) \\\n",
    "                   | df['Publisher'].str.contains('PNAS')].unique(),\n",
    "                  'PNAS'\n",
    "                 )\n",
    "\n",
    "# Nature Publishing Group\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains('Nature P', case=False)) \\\n",
    "                                      | df['Publisher'].str.contains('NPG') \\\n",
    "                                      | (df['Publisher'] == 'Nature')].unique(),\n",
    "                 'Nature Publishing Group'\n",
    "                 )\n",
    "\n",
    "# OUP = Oxford University Press\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains('Oxford',case=False)) \\\n",
    "                                      | (df['Publisher'] == 'OUP')].unique(),\n",
    "                 'Oxford University Press'\n",
    "                 )\n",
    "\n",
    "# PLOS = Public Library of Science\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('PLOS',case=False) \\\n",
    "                   | df['Publisher'].str.contains('Public Library of Science')].unique(),\n",
    "                 'PLOS'\n",
    "                 )\n",
    "\n",
    "# Portland Press\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Portland Press', case=False)].unique(),\n",
    "                 'Portland Press'\n",
    "                 )\n",
    "\n",
    "# PubMed\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('PubMed', case=False)].unique(),\n",
    "                 'PubMed'\n",
    "                 )\n",
    "\n",
    "# The Royal Society (of/for...? Since I have no idea, I'm leaving this as its own entry)\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('The Royal Society', case=False)].unique(),\n",
    "                 'The Royal Society'\n",
    "                 )\n",
    "\n",
    "# Royal Society of Chemistry\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains(('Royal Society for Chemistry'), case=False)) \\\n",
    "                   | (df['Publisher'].str.startswith('RSC'))].unique(),\n",
    "                 'Royal Society of Chemistry'\n",
    "                 )\n",
    "\n",
    "# SAGE Publishing\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Sage', case=False)].unique(),\n",
    "                 'SAGE Publishing'\n",
    "                 )\n",
    "\n",
    "# The Sheridan Press\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Sheridan Press', case=False)].unique(),\n",
    "                 'The Sheridan Press'\n",
    "                 )\n",
    "\n",
    "# Society for General Microbiology\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Society for Genermal Microbiology', case=False)].unique(),\n",
    "                 'Society for General Microbiology'\n",
    "                 )\n",
    "\n",
    "# Society for Neuroscience\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Society (of|for) Neuro', case=False)].unique(),\n",
    "                 'Society for Neuroscience'\n",
    "                 )\n",
    "\n",
    "# Springer Science + Business Media\n",
    "# This pulls in a record for Humana Press--I confirmed this is Humana's parent company.\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.startswith(('Springer','SPRINGER'))].unique(),\n",
    "                 'Springer Science + Business Media'\n",
    "                 )\n",
    "\n",
    "# Taylor and Francis\n",
    "publisher_cleanup(df['Publisher'].loc[(df['Publisher'].str.contains(('Taylor.*?Francis'), case=False)) \\\n",
    "                   | (df['Publisher'].str.contains('T.F'))].unique(),\n",
    "                 'Taylor and Francis'\n",
    "                 )\n",
    "\n",
    "# Wiley, Wiley-Blackwell, Wiley-VCH, John Wiley & Sons, etc. are all basically the same\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('W..ey', case=False)].unique(),\n",
    "                  'Wiley-Blackwell'\n",
    "                 )\n",
    "\n",
    "# Wolters Kluwer\n",
    "publisher_cleanup(df['Publisher'].loc[df['Publisher'].str.contains('Wolters Kluwer', case=False)].unique(),\n",
    "                 'Wolters Kluwer'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Publisher'] = df['Publisher'].replace(publisher_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the five most common journals and the total articles for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsevier                             408\n",
      "PLOS                                 306\n",
      "Wiley-Blackwell                      270\n",
      "Oxford University Press              167\n",
      "Springer Science + Business Media     94\n",
      "Name: Publisher, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_5_journals = df['Publisher'].value_counts()[:5]\n",
    "print(top_5_journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, calculate the mean, median, and standard deviation of the open-access cost per article for each journal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def journal_stats(df,journal):\n",
    "    stats_for = df.loc[df['Publisher'] == journal]['Cost']\n",
    "    these_stats = stats_for.describe()\n",
    "    print(\"Summary statistics for {}:\".format(journal))\n",
    "    print(\"Mean cost: {:.2f}\".format(these_stats['mean']))\n",
    "    print(\"Median cost: {:.2f}\".format(these_stats['50%']))\n",
    "    print(\"Standard deviation: {:.4f}\\n\".format(these_stats['std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for Elsevier:\n",
      "Mean cost: 2435.65\n",
      "Median cost: 2344.32\n",
      "Standard deviation: 794.3210\n",
      "\n",
      "Summary statistics for PLOS:\n",
      "Mean cost: 1124.04\n",
      "Median cost: 1014.38\n",
      "Standard deviation: 403.1324\n",
      "\n",
      "Summary statistics for Wiley-Blackwell:\n",
      "Mean cost: 2010.79\n",
      "Median cost: 2006.64\n",
      "Standard deviation: 372.6783\n",
      "\n",
      "Summary statistics for Oxford University Press:\n",
      "Mean cost: 1844.43\n",
      "Median cost: 2040.00\n",
      "Standard deviation: 512.1148\n",
      "\n",
      "Summary statistics for Springer Science + Business Media:\n",
      "Mean cost: 2023.87\n",
      "Median cost: 1968.11\n",
      "Standard deviation: 271.5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for journal in top_5_journals.index:\n",
    "    journal_stats(df,journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel like these numbers are reasonable--before I noticed the values between 15000.00 and 999999.00, the standard deviations for a couple of the publishers were noticeably larger than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a real bonus round, identify the open access prices paid by subject area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can talk about this. I thought maybe there would be an easy way to divide these articles based on publication or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
