{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import itertools\n",
    "flatten = itertools.chain.from_iterable\n",
    "\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something that is easy to classify, like Yelp reviews. [I found this dataset on Kaggle](https://www.kaggle.com/omkarsabnis/yelp-reviews-dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df = pd.read_csv('yelp-reviews-dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "0     9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1     ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2     6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3     _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4     6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "...                      ...         ...                     ...    ...   \n",
       "9995  VY_tvNUCCXGXQeSvJl757Q  2012-07-28  Ubyfp2RSDYW0g7Mbr8N3iA      3   \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg  2012-01-18  2XyIOQKbVFb6uXQdJ0RzlQ      4   \n",
       "9997  53YGfwmbW73JhFiemNeyzQ  2010-11-16  jyznYkIbpqVmlsZxSDSypA      4   \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA  2012-12-02  5UKq9WQE1qQbJ0DJbc-B6Q      2   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw  2010-10-16  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "0     My wife took me here on my birthday for breakf...  review   \n",
       "1     I have no idea why some people give bad review...  review   \n",
       "2     love the gyro plate. Rice is so good and I als...  review   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4     General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                 ...     ...   \n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "0     rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1     0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2     0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3     uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4     vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "...                      ...   ...     ...    ...  \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow     1       2      0  \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw     0       0      0  \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg     0       0      0  \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ     0       0      0  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>4174</td>\n",
       "      <td>1995</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>6403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>ntN85eu27C04nwyPa8IHtw</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>wxlaY9CGArFFXzYLGBFv1w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This review is for the chain in general. The l...</td>\n",
       "      <td>review</td>\n",
       "      <td>fczQCSmaWF78toLEmb0Zsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.777500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>1.409300</td>\n",
       "      <td>0.701300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.214636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.067861</td>\n",
       "      <td>2.336647</td>\n",
       "      <td>1.907942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id        date               review_id  \\\n",
       "count                    10000       10000                   10000   \n",
       "unique                    4174        1995                   10000   \n",
       "top     ntN85eu27C04nwyPa8IHtw  2011-03-28  wxlaY9CGArFFXzYLGBFv1w   \n",
       "freq                        37          21                       1   \n",
       "mean                       NaN         NaN                     NaN   \n",
       "std                        NaN         NaN                     NaN   \n",
       "min                        NaN         NaN                     NaN   \n",
       "25%                        NaN         NaN                     NaN   \n",
       "50%                        NaN         NaN                     NaN   \n",
       "75%                        NaN         NaN                     NaN   \n",
       "max                        NaN         NaN                     NaN   \n",
       "\n",
       "               stars                                               text  \\\n",
       "count   10000.000000                                              10000   \n",
       "unique           NaN                                               9998   \n",
       "top              NaN  This review is for the chain in general. The l...   \n",
       "freq             NaN                                                  2   \n",
       "mean        3.777500                                                NaN   \n",
       "std         1.214636                                                NaN   \n",
       "min         1.000000                                                NaN   \n",
       "25%         3.000000                                                NaN   \n",
       "50%         4.000000                                                NaN   \n",
       "75%         5.000000                                                NaN   \n",
       "max         5.000000                                                NaN   \n",
       "\n",
       "          type                 user_id          cool        useful  \\\n",
       "count    10000                   10000  10000.000000  10000.000000   \n",
       "unique       1                    6403           NaN           NaN   \n",
       "top     review  fczQCSmaWF78toLEmb0Zsw           NaN           NaN   \n",
       "freq     10000                      38           NaN           NaN   \n",
       "mean       NaN                     NaN      0.876800      1.409300   \n",
       "std        NaN                     NaN      2.067861      2.336647   \n",
       "min        NaN                     NaN      0.000000      0.000000   \n",
       "25%        NaN                     NaN      0.000000      0.000000   \n",
       "50%        NaN                     NaN      0.000000      1.000000   \n",
       "75%        NaN                     NaN      1.000000      2.000000   \n",
       "max        NaN                     NaN     77.000000     76.000000   \n",
       "\n",
       "               funny  \n",
       "count   10000.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.701300  \n",
       "std         1.907942  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max        57.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Drop columns we don't care about, which for this exercise is basically everything but the review text and the rating.\n",
    "\n",
    "We can keep the business_id and use it to get an overall idea of how a business is rated, I suppose.\n",
    "\n",
    "Cool/useful/funny might also provide some insight into the rating, so I am going to try keeping these features too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df.drop(['date','review_id','type','user_id'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Let's just look at 500 rows until we get a better idea of what we're doing.\n",
    "# Otherwise rerunning the parsing thing takes forever\n",
    "yelp_df =  yelp_df.truncate(after=500)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH/NJREFUeJzt3Xm0XFWZ9/HvjyQyyJBgIoQkkKhpNagEjAGkVWQMiAaWSgcHIo0dsaHbAbsFWppJHFtx8bZCo0QCCAFRJE1HMM3g0K8EAoRAQOC+EEhCIBcCgTAaeN4/9r5wKOveW5V7b9Wl9++zVq06tfc+ez91quo8Z6oqRQRmZlaejdodgJmZtYcTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJIJN0tqQT+6mv7SWtkzQkP75e0mf7o+/c368lzeyv/poY9+uSHpX08AD0e15/9tnk+DMl/brFY0rS+ZKekPR/WzDehZJOztP7SFo20GPmsU6UdHYrxupm/A9Juqxd4zdC0iGSftaOsYtIAJKWSXpW0lNdHzhJR0l6+flHxFERcVqDfe3TU5uIeDAiNo+IF/sh9pMlXVjT/wERMaevfTcZx/bAscCkiNi2pm6bnBj2rCmfLWluC8PslaS3SHrVl18iYk5EHNDiUPYEPgBsFxHvbfHYLRMRp0XEUW0M4XTgW10PJH1D0h2S1kv6Wm1jSZ+S9EDegPulpOGVujdIukLS03k98Df9NO+vgF0k7divz7wBRSSA7MMRsQWwA+kN8VXg3P4eRNLQ/u5zkNgeeCwiVtdWRMQjwJeAH0vaFEDS3sBBwD+0Msiuva7XgB2A+yPimWZnbOV77LX8fpa0O7BxRCyqFN8DfAW4qk77dwE/Aj4JbAv8Gfj3SpOzgaeBNwIzSe/3t/V13kjfxp0L/F3fnvEGiIj/9TdgGbBPTdlU4CXgHfnxecDX8/RI4ErgCWAN8HtSsrwgz/MssA74Z2A8EMCRwIPA7yplQ3N/1wPfBG4EngSuALbOdXsCK+rFC0wDXiC9mdYBt1X6+2ye3gj4GvAAsBo4H9gq13XFMTPH9ijwLz0sp63y/J25v6/l/vfJz/mlHMd53cx/JfBdYFOgA5hRqRsLXJ77vh84ulL39a4+gbfkmP8OeCjfvtRDzBcCPyR9oJ/Oy/MjwOK8rB8ETqy0fyj3vy7f3gN8Frg+1w/N9Z/Lz+Fx4MzK/EOAHwCPAfeRElxU6o/Mr99TuX5GnZhnAc8BL+YYTszlR+UxHyNtFY6uienvc31HnT43Ai4DHia9b68H3l6znE7O0/sAy7pZnnXHAiYB/036PPwJ+Ggu3wNYCWxU6ePjwC21r22l/Q05xsXA+3P5vsCtlXbXAX+sPP4jcFCePiG/jk/mWPbs5rmcCpzdTd1c4Gs1Zd8Bzq88fivwPLAZsCXpc/imSv3FvLLO2OB58+MPAPe2fN3Y6gHbcaNOAsjlDwKfz9PnVV7Mb5Iy9rB8ex+gen3xykr2fOD1pJVfV1k1AawE3pHb/AK4MNftSTcJIE+f3NW2Un89rySAvyV9UN8EbA78ErigJrYf57h2ym/Kt3eznM4nJact8rz3AEd2F2ed+ceSVl5XAL+qlG9E+rCfALyOtJJfBuyd6+slgAvyh2en3Gd3H/ILSSvp3fM4GwN7ATvmxzuREt9B1f5r+qiXAK4gJcTxpJVe1+txDHAHMAbYmrSiily3JbAWmJgfjyYdMqsX98tj5sf7kRL4ZGAT0tbktTUxXQWMADat099GwGfya7cJaetzUc1yOjlPN5IAXh4rv69WAofn+nfn1+StgPJr+cFKH5cDX6nz2o7L8+2f452WX5s3kD4Xz+UxX0dKZA/l90BX3fD8uj4AbJv7nEBlxVrzXC6nm40H6ieA/wKOrSl7Nr+H3gM8VVN3HHB5X+fNj9+Yl/tmA7kurL2VdAionodIH+JafyZ9eHeIiD9HxO+7PuE9ODkino6IZ7upvyAi7oiIp4ETgUP76XDFJ4HvR8R9EbEOOB6YUbPrfkpEPBsRtwG3kd6Ur5JjmQEcHxFPRcQy4HvApxsNJCJWAP9KWsF8vlK1O7BlRHwjIl6IiA7S4bcZPXR3SkQ8k2OeAxzWQ9vLI+KPEfFSRDwfEddGxNL8+DbSh/0DjT6P7JsRsTYvh+tJK2aAQ4EzImJlRKwBvl0zXwDvkLRJRKyKiDsbHO+TwE8iYnFEPEdaQXxA0thKm29ExOP13mP5uZ6XX7vnSBsO75b0+gbHr1UdazpwT0ScHxHrI+Jm0h7Kx/LnYi759cnHvffPZbUOB+ZFxNU53qtI78dp+XNxK2ljaypwC2lP4b35dmdEPAGsJyW4HSUNjYj7I+K+bp7DcNKeWKM2JyXwqidJSbVe3dpc19d5qcQ5nBYqPQGMIW3d1fouaav6N5Luk3RcA30tb6L+AdKexciGouzZdrm/at9DgW0qZdWrdp4hvSFrjcwx1fY1psl4lgKPR8SqStkOwPb5BPwTkp4gHT7btm4PSe3y2q7BtkjaPV951SlpLWlru9ll3d0y265mvJenI+JJ0orwaOBhSVdK+qsGx3vV65j7epxXL/9u32OShkj6Tn6/Pkl6/8KGv8eqY+0A7FHz+v0NaSMJ4CLgo5KGAR8FFuaNgVo7AIfV9LMbr7y2vyXtab4/T19PStwfyI+JiLtJFyOcCqyWdLGk7t5Hj/PqlWxv1pH24qq2JK2ce6rr67xU4nyiiXj7rNgEIOk9pA/XH2rr8lbUsRHxJtLx5C/nk5qQtvDq6W0PYVxlenvSXsajpOPWm1XiGgKMaqLfh0gfrGrf64FHepmv1qM5ptq+VjbZTz3LScc3h1duW0TEh3uYp3Z5PdRD29plNJd0mG1cRGwF/IR0qKJe22atIh3qqhcnEfHriNiHtHLsAP6jwX5f9TpK2oJ0OKS6/HuK/XDgQNLhr61Ih7rglefdrOpYy4Fral6/zSPiGICIWEJKmPsDnyAlhHqWAz+t6ef1EfHdXF+bAH5LTQLI410YEXuQDv8MIR2yrWcJ0GgChrTx8vLecU7eGwH3AncDm0qaUGm/U56nr/MCvJ10vqXpiwL6orgEIGlLSQeRVhIXRsTtddoclC8XFGlX7UXSCVBIK9Y3bcDQn5I0SdJmpK2XyyJdJnoPsEm+XnkY6cTrxpX5HgHGVy9ZrXEx8CVJEyRtDnwDuCQi1jcTXI7lUuB0SVtI2gH4MunYcV/9EXhB0rGSNslbq++U9O4e5jlR0qaS3kk6iX1JE+NtAayJiOck7carDzWtBkLShryGkJbRFyVtJ2kE8E9dFZJGS/pwfo1fICX3l7rpp9bFwJGS3iVpY9JK7ffdbEnXswXp/M5jpA2K0xucrxHzSIdcPiFpWL5NlfTWSpuLSFeC7U46GV3PBcAhkvbN74FNJH1QUtcewP+QjvHvDCwircDfAkwhXYiBpLfneTYmHWPvujihnvnUHPrLsW9CWvcNzTF0fbYuBA6W9N586OxU4Of5UGTXxRunSdpM0vuAD/HK56Mv85LjbOl3UaCsBPCfkp4ibYX8C/B94Ihu2k4kXfGwjrTy+lFEXJfrvgl8Le/CfqWJ8S8gnWh+mHQM8x8BImIt6YqLn5C29p4Gqh/6n+f7xyTdUqff2bnv35GurnmODb/08h/y+PeR9owuyv33SU5GB5KO7S4j7W38B3+5W1z1hxzHb0jH469tYsjPA9/Mr/cJpJV2VyxPkV7Dhfk1nNJEvwBnkQ5N3A7cTDr590KuG0JKCKtIK+L3kg4H9SofDz+VdOJyFWmv55NNxPVTXrlqainQb18uy+/R/YFP5dgeJi3D6obKRaS9jwUR8Xg3/SwDDiGdA+skXYRxLHk9lFeUS4Al+VxDkK6c64iIx3I3G5OuuHk0xzGC9HmuN96NwPM1Gxo/JSWNjwMn5elP5PZLSCf555I2FDbm1Z+lo0jv2U7SyntWRPypr/PmDc0ZwDn1nsdA6rqyxWxQkPQW0uGiDT100VKSPgz8ICLe3O5Y7C9JOhD424j4WLtj6Y6kQ4CPR8QnWj62E4ANJoM9AeTd+/eR9hC3JW2x/zYimtkbNBsUSjoEZNYfRDq+/gTpENAS4JS2RmS2gbwHYGZWKO8BmJkValD/0NPIkSNj/Pjx7Q7DzOw15eabb340Ikb11m5QJ4Dx48ezaNGi3huamdnLJD3QeysfAjIzK5YTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUL0mgPx72TdKuk3SUkmn5PLzJN0vaXG+Tc7lknSmpA5JSyTtUulrpqR7823mwD0tMzPrTSNfBHse2Csi1uU/LPmDpK4/LviniKj984cDSL+nPxHYlfT76btK2pr0+9tTSP82dLOked39driZmQ2sXhNA/lOGdfnhsHzr6RfkpgPn5/lukDRc0mjSX70tyH+kjaQFwDTSPyGZWYMuWvhgu0NouU/sun27Q/hfqaFzAPnv2xaT/ulmQUQszFWn58M8Z+S/aIP0P7vVP5Rekcu6K68da5akRZIWdXZ2Nvl0zMysUQ0lgIh4MSImk/4Me6qkdwDHA28D3gNsDXy1PwKKiHMiYkpETBk1qtffMjIzsw3U1FVAEfEEcB0wLSJWRfI86X82p+ZmK4FxldnG5rLuys3MrA0auQpolKTheXpTYF/gT/m4ftcfGh8M3JFnmQccnq8G2g1YGxGrgKuB/SSNkDQC2C+XmZlZGzRyFdBoYI6kIaSEcWlEXCnpWkmjSH+Rt5j0r/cA84EDgQ7gGeAIgIhYI+k04Kbc7tSuE8JmZtZ6jVwFtATYuU75Xt20D+DobupmA7ObjNHMzAaAvwlsZlYoJwAzs0I5AZiZFcoJwMysUIP6T+HNzMA/fzFQvAdgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFBOAGZmhXICMDMrlBOAmVmhek0AkjaRdKOk2yQtlXRKLp8gaaGkDkmXSHpdLt84P+7I9eMrfR2fy++WtP9APSkzM+tdI3sAzwN7RcROwGRgmqTdgG8DZ0TEW4DHgSNz+yOBx3P5GbkdkiYBM4AdgWnAjyQN6c8nY2Zmjes1AUSyLj8clm8B7AVclsvnAAfn6en5Mbl+b0nK5XMj4vmIuB/oAKb2y7MwM7OmNXQOQNIQSYuB1cAC4P8BT0TE+txkBTAmT48BlgPk+rXAG6rldeYxM7MWaygBRMSLETEZGEvaan/bQAUkaZakRZIWdXZ2DtQwZmbFa+oqoIh4ArgO2B0YLqnrT+XHAivz9EpgHECu3wp4rFpeZ57qGOdExJSImDJq1KhmwjMzsyY0chXQKEnD8/SmwL7AXaRE8LHcbCZwRZ6elx+T66+NiMjlM/JVQhOAicCN/fVEzMysOUN7b8JoYE6+Ymcj4NKIuFLSncBcSV8HbgXOze3PBS6Q1AGsIV35Q0QslXQpcCewHjg6Il7s36djZmaN6jUBRMQSYOc65fdR5yqeiHgO+Hg3fZ0OnN58mGZm1t/8TWAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFBOAGZmhXICMDMrlBOAmVmhnADMzArlBGBmVignADOzQjkBmJkVygnAzKxQTgBmZoVyAjAzK1SvCUDSOEnXSbpT0lJJX8jlJ0taKWlxvh1Ymed4SR2S7pa0f6V8Wi7rkHTcwDwlMzNrxNAG2qwHjo2IWyRtAdwsaUGuOyMi/q3aWNIkYAawI7Ad8N+S/ipX/xDYF1gB3CRpXkTc2R9PxMzMmtNrAoiIVcCqPP2UpLuAMT3MMh2YGxHPA/dL6gCm5rqOiLgPQNLc3NYJwMysDZo6ByBpPLAzsDAXHSNpiaTZkkbksjHA8spsK3JZd+W1Y8yStEjSos7OzmbCMzOzJjScACRtDvwC+GJEPAmcBbwZmEzaQ/hefwQUEedExJSImDJq1Kj+6NLMzOpo5BwAkoaRVv4/i4hfAkTEI5X6HwNX5ocrgXGV2cfmMnooNzOzFmvkKiAB5wJ3RcT3K+WjK80OAe7I0/OAGZI2ljQBmAjcCNwETJQ0QdLrSCeK5/XP0zAzs2Y1sgewB/Bp4HZJi3PZCcBhkiYDASwDPgcQEUslXUo6ubseODoiXgSQdAxwNTAEmB0RS/vxuZiZWRMauQroD4DqVM3vYZ7TgdPrlM/vaT4zM2sdfxPYzKxQTgBmZoVyAjAzK5QTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFBOAGZmhXICMDMrlBOAmVmhek0AksZJuk7SnZKWSvpCLt9a0gJJ9+b7Eblcks6U1CFpiaRdKn3NzO3vlTRz4J6WmZn1ppE9gPXAsRExCdgNOFrSJOA44JqImAhckx8DHABMzLdZwFmQEgZwErArMBU4qStpmJlZ6/WaACJiVUTckqefAu4CxgDTgTm52Rzg4Dw9HTg/khuA4ZJGA/sDCyJiTUQ8DiwApvXrszEzs4Y1dQ5A0nhgZ2AhsE1ErMpVDwPb5OkxwPLKbCtyWXfltWPMkrRI0qLOzs5mwjMzsyY0nAAkbQ78AvhiRDxZrYuIAKI/AoqIcyJiSkRMGTVqVH90aWZmdTSUACQNI638fxYRv8zFj+RDO+T71bl8JTCuMvvYXNZduZmZtUEjVwEJOBe4KyK+X6maB3RdyTMTuKJSfni+Gmg3YG0+VHQ1sJ+kEfnk7365zMzM2mBoA232AD4N3C5pcS47AfgWcKmkI4EHgENz3XzgQKADeAY4AiAi1kg6Dbgptzs1Itb0y7MwM7Om9ZoAIuIPgLqp3rtO+wCO7qav2cDsZgI0M7OB4W8Cm5kVygnAzKxQTgBmZoVyAjAzK5QTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFBOAGZmhXICMDMrlBOAmVmhek0AkmZLWi3pjkrZyZJWSlqcbwdW6o6X1CHpbkn7V8qn5bIOScf1/1MxM7NmNLIHcB4wrU75GRExOd/mA0iaBMwAdszz/EjSEElDgB8CBwCTgMNyWzMza5OhvTWIiN9JGt9gf9OBuRHxPHC/pA5gaq7riIj7ACTNzW3vbDpiMzPrF305B3CMpCX5ENGIXDYGWF5psyKXdVf+FyTNkrRI0qLOzs4+hGdmZj3Z0ARwFvBmYDKwCvhefwUUEedExJSImDJq1Kj+6tbMzGr0egionoh4pGta0o+BK/PDlcC4StOxuYweys022EULH2x3CGavWRu0ByBpdOXhIUDXFULzgBmSNpY0AZgI3AjcBEyUNEHS60gniudteNhmZtZXve4BSLoY2BMYKWkFcBKwp6TJQADLgM8BRMRSSZeSTu6uB46OiBdzP8cAVwNDgNkRsbTfn42ZmTWskauADqtTfG4P7U8HTq9TPh+Y31R0ZmY2YPxNYDOzQjkBmJkVygnAzKxQTgBmZoVyAjAzK5QTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFBOAGZmheo1AUiaLWm1pDsqZVtLWiDp3nw/IpdL0pmSOiQtkbRLZZ6Zuf29kmYOzNMxM7NGNbIHcB4wrabsOOCaiJgIXJMfAxwATMy3WcBZkBIGcBKwKzAVOKkraZiZWXv0mgAi4nfAmpri6cCcPD0HOLhSfn4kNwDDJY0G9gcWRMSaiHgcWMBfJhUzM2uhDT0HsE1ErMrTDwPb5OkxwPJKuxW5rLvyvyBplqRFkhZ1dnZuYHhmZtabPp8EjogAoh9i6ervnIiYEhFTRo0a1V/dmplZjQ1NAI/kQzvk+9W5fCUwrtJubC7rrtzMzNpkQxPAPKDrSp6ZwBWV8sPz1UC7AWvzoaKrgf0kjcgnf/fLZWZm1iZDe2sg6WJgT2CkpBWkq3m+BVwq6UjgAeDQ3Hw+cCDQATwDHAEQEWsknQbclNudGhG1J5atH1y08MF2h2BmrxG9JoCIOKybqr3rtA3g6G76mQ3Mbio6MzMbMP4msJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaF6/Sbwa5l/FsHMrHveAzAzK5QTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaH6lAAkLZN0u6TFkhblsq0lLZB0b74fkcsl6UxJHZKWSNqlP56AmZltmP7YA/hgREyOiCn58XHANRExEbgmPwY4AJiYb7OAs/phbDMz20ADcQhoOjAnT88BDq6Unx/JDcBwSaMHYHwzM2tAXxNAAL+RdLOkWblsm4hYlacfBrbJ02OA5ZV5V+SyV5E0S9IiSYs6Ozv7GJ6ZmXWnrz8H/dcRsVLSG4EFkv5UrYyIkBTNdBgR5wDnAEyZMqWpec3MrHF92gOIiJX5fjVwOTAVeKTr0E6+X52brwTGVWYfm8vMzKwNNjgBSHq9pC26poH9gDuAecDM3GwmcEWengccnq8G2g1YWzlUZGZmLdaXQ0DbAJdL6urnooi4StJNwKWSjgQeAA7N7ecDBwIdwDPAEX0Y28zM+miDE0BE3AfsVKf8MWDvOuUBHL2h45mZWf/yN4HNzArlBGBmVignADOzQjkBmJkVygnAzKxQTgBmZoVyAjAzK5QTgJlZoZwAzMwK5QRgZlYoJwAzs0I5AZiZFcoJwMysUE4AZmaFcgIwMyuUE4CZWaGcAMzMCuUEYGZWKCcAM7NCOQGYmRXKCcDMrFAtTwCSpkm6W1KHpONaPb6ZmSUtTQCShgA/BA4AJgGHSZrUyhjMzCxp9R7AVKAjIu6LiBeAucD0FsdgZmbA0BaPNwZYXnm8Ati12kDSLGBWfrhO0t19GG8k8Ggf5h8ojqs5jqs5jqs5gzKuT/Ytrh0aadTqBNCriDgHOKc/+pK0KCKm9Edf/clxNcdxNcdxNafkuFp9CGglMK7yeGwuMzOzFmt1ArgJmChpgqTXATOAeS2OwczMaPEhoIhYL+kY4GpgCDA7IpYO4JD9cihpADiu5jiu5jiu5hQblyJioMcwM7NByN8ENjMrlBOAmVmhXvMJQNJsSasl3dFNvSSdmX96YomkXQZJXHtKWitpcb79a4viGifpOkl3Sloq6Qt12rR8mTUYV8uXmaRNJN0o6bYc1yl12mws6ZK8vBZKGj9I4vqMpM7K8vrsQMdVGXuIpFslXVmnruXLq4GY2rmslkm6PY+7qE79wH0eI+I1fQPeD+wC3NFN/YHArwEBuwELB0lcewJXtmF5jQZ2ydNbAPcAk9q9zBqMq+XLLC+DzfP0MGAhsFtNm78Hzs7TM4BLBklcnwH+vdXvsTz2l4GL6r1e7VheDcTUzmW1DBjZQ/2AfR5f83sAEfE7YE0PTaYD50dyAzBc0uhBEFdbRMSqiLglTz8F3EX6hnZVy5dZg3G1XF4G6/LDYflWe+XEdGBOnr4M2FuSBkFcbSFpLPAh4CfdNGn58mogpsFswD6Pr/kE0IB6Pz/R9hVLtnvehf+1pB1bPXje9d6ZtPVY1dZl1kNc0IZllg8dLAZWAwsiotvlFRHrgbXAGwZBXAAfzYcNLpM0rk79QPgB8M/AS93Ut2N59RYTtGdZQUrcv5F0s9JP4dQasM9jCQlgsLoF2CEidgL+D/CrVg4uaXPgF8AXI+LJVo7dk17iassyi4gXI2Iy6ZvrUyW9oxXj9qaBuP4TGB8R7wIW8MpW94CRdBCwOiJuHuixGtVgTC1fVhV/HRG7kH4l+WhJ72/VwCUkgEH58xMR8WTXLnxEzAeGSRrZirElDSOtZH8WEb+s06Qty6y3uNq5zPKYTwDXAdNqql5eXpKGAlsBj7U7roh4LCKezw9/Ary7BeHsAXxE0jLSr/3uJenCmjatXl69xtSmZdU19sp8vxq4nPSryVUD9nksIQHMAw7PZ9J3A9ZGxKp2ByVp267jnpKmkl6LAV9p5DHPBe6KiO9306zly6yRuNqxzCSNkjQ8T28K7Av8qabZPGBmnv4YcG3ks3ftjKvmOPFHSOdVBlREHB8RYyNiPOkE77UR8amaZi1dXo3E1I5llcd9vaQtuqaB/YDaKwcH7PM46H4NtFmSLiZdHTJS0grgJNIJMSLibGA+6Sx6B/AMcMQgietjwOclrQeeBWYM9Eoj2wP4NHB7Pn4McAKwfSW2diyzRuJqxzIbDcxR+jOjjYBLI+JKSacCiyJiHilxXSCpg3Tif8YAx9RoXP8o6SPA+hzXZ1oQV12DYHn1FlO7ltU2wOV5u2YocFFEXCXpKBj4z6N/CsLMrFAlHAIyM7M6nADMzArlBGBmVignADOzQjkBmJkVygnArAeSvihps3bHYTYQfBmoWQ/yt0enRMSjTcwzJCJeHLiozPrHa/6LYGb9JX8T81LSV+2HAD8HtgOuk/RoRHxQ0lnAe4BNgcsi4qQ87zLgEtI3cr8j6Y3AUaQvFt0ZEW35spNZT5wAzF4xDXgoIj4EIGkr0rcuP1jZA/iXiFiTv4F7jaR3RcSSXPdY/lEvJD0ETIiI57t+ssFssPE5ALNX3A7sK+nbkt4XEWvrtDlU0i3ArcCOwKRK3SWV6SXAzyR9irQXYDboOAGYZRFxD+lf3G4Hvq6av5yUNAH4CrB3/tng/wI2qTR5ujL9IeCHub+b8q9emg0qTgBmmaTtgGci4kLgu6SV91Okv6gE2JK0kl8raRvS77fX62cjYFxEXAd8lfRzx5sPcPhmTfNWidkr3gl8V9JLwJ+BzwO7A1dJeiifBL6V9LPLy4H/6aafIcCF+RyCgDPzb/abDSq+DNTMrFA+BGRmVignADOzQjkBmJkVygnAzKxQTgBmZoVyAjAzK5QTgJlZof4/aM8FWkr6PvsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(yelp_df['stars'],bins=5,norm_hist=False,kde=False)\\\n",
    "             .set_title('Distribution of Yelp ratings for all reviews ({})'.format(yelp_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "# Remove double dashes\n",
    "    text = re.sub(r'--',' ',text)\n",
    "# Strip lines encased in brackets\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "# Random asterisks and dollar signs appear throughout\n",
    "    text = re.sub('[\\*\\$]*', '', text)\n",
    "# Remove lines that are nothing but spaces and digits\n",
    "    text = re.sub(r'^\\s*[0-9]+\\s*$', '', text,flags=re.M)\n",
    "# Strip EOF characters\n",
    "    text = re.sub(r\"\\x1a\",\"\",text)\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df['text'] = yelp_df['text'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df['parsed_text'] = yelp_df['text'].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (My, wife, took, me, here, on, my, birthday, f...\n",
       "1       (I, have, no, idea, why, some, people, give, b...\n",
       "2       (love, the, gyro, plate, ., Rice, is, so, good...\n",
       "3       (Rosie, ,, Dakota, ,, and, I, LOVE, Chaparral,...\n",
       "4       (General, Manager, Scott, Petello, is, a, good...\n",
       "                              ...                        \n",
       "9995    (First, visit, ..., Had, lunch, here, today, -...\n",
       "9996    (Should, be, called, house, of, deliciousness,...\n",
       "9997    (I, recently, visited, Olive, and, Ivy, for, b...\n",
       "9998    (My, nephew, just, moved, to, Scottsdale, rece...\n",
       "9999    (4, -, 5, locations, .., all, 4.5, star, avera...\n",
       "Name: parsed_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['parsed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_digit\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = bag_of_words(list(flatten(yelp_df['parsed_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'place',\n",
       " 'food',\n",
       " 'like',\n",
       " 'great',\n",
       " 'time',\n",
       " 'order',\n",
       " 'go',\n",
       " 'come',\n",
       " 'service',\n",
       " 'try',\n",
       " 'love',\n",
       " 'get',\n",
       " 'think',\n",
       " 'eat',\n",
       " 'nice',\n",
       " 'little',\n",
       " 'look',\n",
       " 'restaurant',\n",
       " 'know',\n",
       " 'want',\n",
       " 'price',\n",
       " 'find',\n",
       " 'drink',\n",
       " 'thing',\n",
       " 'pretty',\n",
       " 'wait',\n",
       " 'menu',\n",
       " 'bar',\n",
       " 'people',\n",
       " 'night',\n",
       " 'friendly',\n",
       " 'way',\n",
       " 'staff',\n",
       " 'day',\n",
       " 'taste',\n",
       " 'chicken',\n",
       " 'table',\n",
       " 'feel',\n",
       " 'friend',\n",
       " 'ask',\n",
       " 'salad',\n",
       " 'right',\n",
       " 'say',\n",
       " 'pizza',\n",
       " 'need',\n",
       " 'cheese',\n",
       " 'sauce',\n",
       " 'lot',\n",
       " 'delicious',\n",
       " 'experience',\n",
       " 'work',\n",
       " 'hour',\n",
       " 'star',\n",
       " 'take',\n",
       " 'lunch',\n",
       " 'bad',\n",
       " 'meal',\n",
       " 'fry',\n",
       " 'enjoy',\n",
       " 'fresh',\n",
       " 'well',\n",
       " 'sandwich',\n",
       " 'sure',\n",
       " 'definitely',\n",
       " 'review',\n",
       " 'dish',\n",
       " 'tell',\n",
       " 'area',\n",
       " 'year',\n",
       " 'location',\n",
       " 'bit',\n",
       " 'serve',\n",
       " 'new',\n",
       " 'flavor',\n",
       " 'sit',\n",
       " 'small',\n",
       " 'amazing',\n",
       " 'happy',\n",
       " 'big',\n",
       " 'beer',\n",
       " 'visit',\n",
       " 'walk',\n",
       " 'favorite',\n",
       " 'burger',\n",
       " 'dinner',\n",
       " 'store',\n",
       " 'leave',\n",
       " 'check',\n",
       " 'minute',\n",
       " 'give',\n",
       " 'recommend',\n",
       " 'home',\n",
       " 'Phoenix',\n",
       " 'bring',\n",
       " 'special',\n",
       " 'server',\n",
       " 'clean',\n",
       " 'tasty',\n",
       " 'long',\n",
       " 'wine',\n",
       " 'room',\n",
       " 'bread',\n",
       " 'meat',\n",
       " 'hot',\n",
       " 'open',\n",
       " 'selection',\n",
       " 'awesome',\n",
       " 'start',\n",
       " 'make',\n",
       " 'worth',\n",
       " 'sweet',\n",
       " 'kind',\n",
       " 'see',\n",
       " 'different',\n",
       " 'end',\n",
       " 'atmosphere',\n",
       " 'large',\n",
       " 'close',\n",
       " 'ok',\n",
       " 'coffee',\n",
       " 'item',\n",
       " 'stop',\n",
       " 'live',\n",
       " 'actually',\n",
       " 'offer',\n",
       " 'old',\n",
       " 'pay',\n",
       " 'excellent',\n",
       " 'plate',\n",
       " 'breakfast',\n",
       " 'huge',\n",
       " 'customer',\n",
       " 'probably',\n",
       " 'quality',\n",
       " 'decide',\n",
       " 'free',\n",
       " 'cool',\n",
       " 'let',\n",
       " 'maybe',\n",
       " 'perfect',\n",
       " 'expect',\n",
       " 'roll',\n",
       " 'guy',\n",
       " 'spot',\n",
       " 'seat',\n",
       " 'week',\n",
       " 'kid',\n",
       " 'super',\n",
       " 'high',\n",
       " 'rice',\n",
       " 'usually',\n",
       " 'fun',\n",
       " 'drive',\n",
       " 'stuff',\n",
       " 'shop',\n",
       " 'away',\n",
       " 'outside',\n",
       " 'inside',\n",
       " 'have',\n",
       " 'potato',\n",
       " 'far',\n",
       " 'cream',\n",
       " 'Scottsdale',\n",
       " 'cook',\n",
       " 'water',\n",
       " 'course',\n",
       " 'sushi',\n",
       " 'soup',\n",
       " 'family',\n",
       " 'cheap',\n",
       " 'stay',\n",
       " 'half',\n",
       " 'beef',\n",
       " 'oh',\n",
       " 'couple',\n",
       " 'house',\n",
       " 'return',\n",
       " 'help',\n",
       " 'buy',\n",
       " 'fan',\n",
       " 'taco',\n",
       " 'chip',\n",
       " 'overall',\n",
       " 'owner',\n",
       " 'patio',\n",
       " 'portion',\n",
       " 'add',\n",
       " 'parking',\n",
       " 'run',\n",
       " 'dessert',\n",
       " 'decent',\n",
       " 'choice',\n",
       " 'busy',\n",
       " 'town',\n",
       " 'care',\n",
       " 'hard',\n",
       " 'use',\n",
       " 'line',\n",
       " 'appetizer']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "# Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences['parsed_text']\n",
    "    df['text_source'] = sentences['stars']\n",
    "    df.loc[:, common_words] = 0\n",
    "\n",
    "# Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "# Convert the sentence to lemmas, then filter out punctuation,\n",
    "# stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct and\n",
    "                     not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "# Capture the amount of punctuation (check the length of this list)\n",
    "        punctuation = [token.lemma_\n",
    "                       for token in sentence\n",
    "                       if token.is_punct]\n",
    "\n",
    "        capwords = 0\n",
    "    \n",
    "# Populate values for individual word count\n",
    "        word_count = Counter(words)\n",
    "        for word in word_count:\n",
    "            df.loc[i,word] = word_count[word]\n",
    "\n",
    "# Capture words in all caps that are longer than two characters.\n",
    "# We don't want to capture numbers, or Spacy's own PRON token for pronouns, or numbers--\n",
    "# Austen is apparently fond of mentioning years, which look the same in all caps ;)\n",
    "            if ((word == str.upper(word)) &\n",
    "               (word != '-PRON-') & \n",
    "               (len(word) > 2) &\n",
    "               (not word.isnumeric())):\n",
    "                capwords += 1\n",
    "            \n",
    "# Add sentence-level word count, punctuation\n",
    "        df.loc[i,'sentence_length'] = len(sentence)\n",
    "        df.loc[i,'sentence_punctuation'] = len(punctuation)\n",
    "        df.loc[i,'sentence_capwords'] = capwords\n",
    "\n",
    "# This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n",
      "Processing row 1000\n",
      "Processing row 1050\n",
      "Processing row 1100\n",
      "Processing row 1150\n",
      "Processing row 1200\n",
      "Processing row 1250\n",
      "Processing row 1300\n",
      "Processing row 1350\n",
      "Processing row 1400\n",
      "Processing row 1450\n",
      "Processing row 1500\n",
      "Processing row 1550\n",
      "Processing row 1600\n",
      "Processing row 1650\n",
      "Processing row 1700\n",
      "Processing row 1750\n",
      "Processing row 1800\n",
      "Processing row 1850\n",
      "Processing row 1900\n",
      "Processing row 1950\n",
      "Processing row 2000\n",
      "Processing row 2050\n",
      "Processing row 2100\n",
      "Processing row 2150\n",
      "Processing row 2200\n",
      "Processing row 2250\n",
      "Processing row 2300\n",
      "Processing row 2350\n",
      "Processing row 2400\n",
      "Processing row 2450\n",
      "Processing row 2500\n",
      "Processing row 2550\n",
      "Processing row 2600\n",
      "Processing row 2650\n",
      "Processing row 2700\n",
      "Processing row 2750\n",
      "Processing row 2800\n",
      "Processing row 2850\n",
      "Processing row 2900\n",
      "Processing row 2950\n",
      "Processing row 3000\n",
      "Processing row 3050\n",
      "Processing row 3100\n",
      "Processing row 3150\n",
      "Processing row 3200\n",
      "Processing row 3250\n",
      "Processing row 3300\n",
      "Processing row 3350\n",
      "Processing row 3400\n",
      "Processing row 3450\n",
      "Processing row 3500\n",
      "Processing row 3550\n",
      "Processing row 3600\n",
      "Processing row 3650\n",
      "Processing row 3700\n",
      "Processing row 3750\n",
      "Processing row 3800\n",
      "Processing row 3850\n",
      "Processing row 3900\n",
      "Processing row 3950\n",
      "Processing row 4000\n",
      "Processing row 4050\n",
      "Processing row 4100\n",
      "Processing row 4150\n",
      "Processing row 4200\n",
      "Processing row 4250\n",
      "Processing row 4300\n",
      "Processing row 4350\n",
      "Processing row 4400\n",
      "Processing row 4450\n",
      "Processing row 4500\n",
      "Processing row 4550\n",
      "Processing row 4600\n",
      "Processing row 4650\n",
      "Processing row 4700\n",
      "Processing row 4750\n",
      "Processing row 4800\n",
      "Processing row 4850\n",
      "Processing row 4900\n",
      "Processing row 4950\n",
      "Processing row 5000\n",
      "Processing row 5050\n",
      "Processing row 5100\n",
      "Processing row 5150\n",
      "Processing row 5200\n",
      "Processing row 5250\n",
      "Processing row 5300\n",
      "Processing row 5350\n",
      "Processing row 5400\n",
      "Processing row 5450\n",
      "Processing row 5500\n",
      "Processing row 5550\n",
      "Processing row 5600\n",
      "Processing row 5650\n",
      "Processing row 5700\n",
      "Processing row 5750\n",
      "Processing row 5800\n",
      "Processing row 5850\n",
      "Processing row 5900\n",
      "Processing row 5950\n",
      "Processing row 6000\n",
      "Processing row 6050\n",
      "Processing row 6100\n",
      "Processing row 6150\n",
      "Processing row 6200\n",
      "Processing row 6250\n",
      "Processing row 6300\n",
      "Processing row 6350\n",
      "Processing row 6400\n",
      "Processing row 6450\n",
      "Processing row 6500\n",
      "Processing row 6550\n",
      "Processing row 6600\n",
      "Processing row 6650\n",
      "Processing row 6700\n",
      "Processing row 6750\n",
      "Processing row 6800\n",
      "Processing row 6850\n",
      "Processing row 6900\n",
      "Processing row 6950\n",
      "Processing row 7000\n",
      "Processing row 7050\n",
      "Processing row 7100\n",
      "Processing row 7150\n",
      "Processing row 7200\n",
      "Processing row 7250\n",
      "Processing row 7300\n",
      "Processing row 7350\n",
      "Processing row 7400\n",
      "Processing row 7450\n",
      "Processing row 7500\n",
      "Processing row 7550\n",
      "Processing row 7600\n",
      "Processing row 7650\n",
      "Processing row 7700\n",
      "Processing row 7750\n",
      "Processing row 7800\n",
      "Processing row 7850\n",
      "Processing row 7900\n",
      "Processing row 7950\n",
      "Processing row 8000\n",
      "Processing row 8050\n",
      "Processing row 8100\n",
      "Processing row 8150\n",
      "Processing row 8200\n",
      "Processing row 8250\n",
      "Processing row 8300\n",
      "Processing row 8350\n",
      "Processing row 8400\n",
      "Processing row 8450\n",
      "Processing row 8500\n",
      "Processing row 8550\n",
      "Processing row 8600\n",
      "Processing row 8650\n",
      "Processing row 8700\n",
      "Processing row 8750\n",
      "Processing row 8800\n",
      "Processing row 8850\n",
      "Processing row 8900\n",
      "Processing row 8950\n",
      "Processing row 9000\n",
      "Processing row 9050\n",
      "Processing row 9100\n",
      "Processing row 9150\n",
      "Processing row 9200\n",
      "Processing row 9250\n",
      "Processing row 9300\n",
      "Processing row 9350\n",
      "Processing row 9400\n",
      "Processing row 9450\n",
      "Processing row 9500\n",
      "Processing row 9550\n",
      "Processing row 9600\n",
      "Processing row 9650\n",
      "Processing row 9700\n",
      "Processing row 9750\n",
      "Processing row 9800\n",
      "Processing row 9850\n",
      "Processing row 9900\n",
      "Processing row 9950\n"
     ]
    }
   ],
   "source": [
    "word_counts = bow_features(yelp_df[['parsed_text','stars']], common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cool/funny/useful features from the dataset to the bag of words dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.concat([word_counts,yelp_df[['cool','funny','useful']]],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning models (using bag of words)\n",
    "\n",
    "These models all perform about the same--which is to say, not very well. \n",
    "\n",
    "I started off running with just the first 500 reviews, until I was sure I processed the text correctly. When I threw the entire 10,000 record dataset at these models, I noticed the scores went up significantly, and overfitting was much less of an issue (the scores were much more consistent across folds for a given model).\n",
    "\n",
    "My hope is that by incorporating tf-idf, I can improve on these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.45209581 0.43956044 0.44355644 0.43356643 0.44155844 0.46153846\n",
      " 0.458      0.46192385 0.42785571 0.46740221]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",rfc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.448705779390155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.47804391 0.48651349 0.47052947 0.47352647 0.48451548 0.5004995\n",
      " 0.474      0.49599198 0.46292585 0.48545637]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# As I understand it, 'liblinear' is good for smaller datasets, and it can handle l1 penalty\n",
    "lr = LogisticRegression(penalty='l1',multi_class='auto',solver='liblinear')\n",
    "\n",
    "lr_scores = cross_val_score(lr, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48120025325387294"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation scores:  [0.46506986 0.46153846 0.45354645 0.46953047 0.46053946 0.48851149\n",
      " 0.46       0.46492986 0.44188377 0.46940822]\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "clf_scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(\"Cross_validation scores: \",clf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634958045874306"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf setup\n",
    "\n",
    "Honestly, I didn't fully understand what to do here.\n",
    "\n",
    "[This web page about the difference between TfidfTransformer and TfidfVectorizer](https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Xc2nIFlKhqs) helped a _lot_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a model similar to the one we built in the exercises\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             analyzer='word',\n",
    "                             stop_words='english', #nlp.Defaults.stop_words, # use the same stop words as BoW?\n",
    "                             lowercase=True, #convert everything to lower case\n",
    "                             use_idf=True,\n",
    "                             norm='l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 15791\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "yelp_tfidf = vectorizer.fit_transform(yelp_df['text'])\n",
    "print(\"Number of features: %d\" % yelp_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15791)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine one of the reviews and the way its words were weighted, and decide whether it makes sense, before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent. The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure. Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning. It looked like the place fills up pretty quickly so the earlier you get here the better. Do yourself a favor and get their Bloody Mary. It was phenomenal and simply the best I\\'ve ever had. I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it. It was amazing. While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious. It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete. It was the best \"toast\" I\\'ve ever had. Anyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.loc[0,'stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>excellent</td>\n",
       "      <td>0.264846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>quickly</td>\n",
       "      <td>0.220870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>griddled</td>\n",
       "      <td>0.206575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>overlooking</td>\n",
       "      <td>0.180857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fills</td>\n",
       "      <td>0.174122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>famed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>familiar</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>familiarity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>families</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>zuzu</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15791 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tfidf\n",
       "excellent    0.264846\n",
       "quickly      0.220870\n",
       "griddled     0.206575\n",
       "overlooking  0.180857\n",
       "fills        0.174122\n",
       "...               ...\n",
       "famed        0.000000\n",
       "familiar     0.000000\n",
       "familiarity  0.000000\n",
       "families     0.000000\n",
       "zuzu         0.000000\n",
       "\n",
       "[15791 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first vector out (for the first document)\n",
    "first_vector_tfidfvectorizer=yelp_tfidf[0]\n",
    " \n",
    "# place tf-idf values in a pandas data frame\n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 15,000 features now! In the exercises, we used SVD to reduce the number of features. I think this might make it easier for a random forest model (as one example) to handle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_tfidf\n",
    "Y = yelp_df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd = TruncatedSVD(130)\n",
    "#lsa = make_pipeline(svd, Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm interested to see whether applying SVD improves cross-validation scores for the same models I tried earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.51896208 0.4995005  0.4985015  0.53046953 0.51848152 0.51248751\n",
      " 0.513      0.53707415 0.50601202 0.53460381]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2',multi_class='auto',solver='saga')\n",
    "\n",
    "lr_scores = cross_val_score(lr, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5169092619067854"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs well. I wanted to try some different parameters and a different solver, to see whether I could improve on its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.51896208 0.4995005  0.4985015  0.53046953 0.51848152 0.51248751\n",
      " 0.512      0.53707415 0.50601202 0.53560682]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2',multi_class='auto',solver='lbfgs',max_iter=1000)\n",
    "\n",
    "lr_scores = cross_val_score(lr, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5169095628094936"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.46606786 0.46053946 0.46253746 0.47452547 0.48651349 0.48051948\n",
      " 0.467      0.48296593 0.43887776 0.48144433]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",rfc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4700991249280569"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation scores:  [0.4740519  0.49450549 0.47752248 0.4985015  0.49450549 0.48251748\n",
      " 0.467      0.50400802 0.47094188 0.47642929]\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "clf_scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(\"Cross_validation scores: \",clf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4839983531423223"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model is the winner for both techniques, and tf-idf gave better results than bag of words, so let's focus on that model and that data prep technique. Unfortunately, even the \"winner\" doesn't do very well at predicting the number of stars a review should have. :)\n",
    "\n",
    "The solver used in logistic regression doesn't seem to have much of an effect on the results.\n",
    "\n",
    "What if we were a little less ambitious, and only classified reviews as positive/negative instead of assigning stars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = yelp_df['stars'].apply(lambda x: 0 if x < 4 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.82917083 0.82217782 0.82917083 0.818      0.829      0.825\n",
      " 0.836      0.83483483 0.80880881 0.83783784]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2',multi_class='auto',solver='saga')\n",
    "\n",
    "lr_scores = cross_val_score(lr, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.82917083 0.82217782 0.82917083 0.818      0.829      0.825\n",
      " 0.836      0.83483483 0.80880881 0.83783784]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2',multi_class='auto',solver='lbfgs',max_iter=1000)\n",
    "\n",
    "lr_scores = cross_val_score(lr, X, Y, cv=10)\n",
    "print(\"Cross-validation scores: \",lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8270000962000964"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results certainly look better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
